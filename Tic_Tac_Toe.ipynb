{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4xf2Ff+8p5E6jEs2593o9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramesh1703/AlgoCasts/blob/master/Tic_Tac_Toe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install anthropic google-generativeai gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ6I_rjCRFSW",
        "outputId": "838a109a-ce8c-4ac6-e69d-3a04f577fdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/292.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m286.7/292.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "YKw07P0DRaD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_FRONTIERS = [\"GPT-Frontier\", \"Claude-Frontier\", \"Gemini-Frontier\", \"Mistral-Frontier\"]"
      ],
      "metadata": {
        "id": "JGtXqBo-Rbyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_map(model_name):\n",
        "    \"\"\"Maps a friendly model name to its API identifier.\"\"\"\n",
        "    return {\n",
        "        \"GPT-Frontier\": \"gpt-4o\",\n",
        "        \"Claude-Frontier\": \"claude-3-5-sonnet-20241022\",\n",
        "        \"Gemini-Frontier\": \"gemini-1.5-flash\",\n",
        "    }.get(model_name, \"gpt-4o\")"
      ],
      "metadata": {
        "id": "L3gWiRYSRd5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_token = userdata.get('OPENAI_API_KEY')\n",
        "anthropic_token = userdata.get('ANTHROPIC_API_KEY')\n",
        "gemini_token = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "openai_client = OpenAI(api_key=openai_token)\n",
        "anthropic_client = Anthropic(api_key=anthropic_token)\n",
        "genai.configure(api_key=gemini_token)"
      ],
      "metadata": {
        "id": "2c4owqLYRgc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empty_board():\n",
        "    \"\"\"Returns an empty 3x3 Tic-Tac-Toe board.\"\"\"\n",
        "    return [[\"\" for _ in range(3)] for _ in range(3)]"
      ],
      "metadata": {
        "id": "RaWUm6bgRh51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_winner(board):\n",
        "    \"\"\"Checks for a winner or a draw on the board.\"\"\"\n",
        "    lines = (\n",
        "        board +\n",
        "        list(zip(*board)) +\n",
        "        [[board[i][i] for i in range(3)]] +\n",
        "        [[board[i][2 - i] for i in range(3)]]\n",
        "    )\n",
        "\n",
        "    for line in lines:\n",
        "        if line[0] != '' and line.count(line[0]) == 3:\n",
        "            return line[0]\n",
        "\n",
        "    if all(cell != \"\" for row in board for cell in row):\n",
        "        return \"Draw\"\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "baLxNEOMRjlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_board_markdown(board):\n",
        "    \"\"\"Converts the board list into a Markdown table string.\"\"\"\n",
        "    markdown_str = \"| 0 | 1 | 2 |\\n|---|---|---|\\n\"\n",
        "    for r_idx, row in enumerate(board):\n",
        "        row_str = \"|\"\n",
        "        for c_idx, cell in enumerate(row):\n",
        "            display_char = cell if cell != \"\" else \"&nbsp;&nbsp;\"\n",
        "            row_str += f\" {display_char} |\"\n",
        "        markdown_str += row_str + \"\\n\"\n",
        "    return markdown_str"
      ],
      "metadata": {
        "id": "C8V2bcp_Rl1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_move(board, symbol, model_name=\"gpt-4o\"):\n",
        "    \"\"\"\n",
        "    Gets the LLM's move and updates the board.\n",
        "    Returns the updated board and the raw LLM response text.\n",
        "    \"\"\"\n",
        "    board_str = \"\\n\".join(\n",
        "        \" \".join(cell or \".\" for cell in row)\n",
        "        for row in board\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are playing Tic-Tac-Toe as {symbol}.\\n\"\n",
        "        f\"Here is the current board:\\n{board_str}\\n\"\n",
        "        f\"Reply with your move as two numbers 0-2 (row and column) separated by a space, \"\n",
        "        f\"like '1 2'. Do not say anything else.\"\n",
        "    )\n",
        "\n",
        "    move_text = None\n",
        "    try:\n",
        "        if model_name.startswith(\"gpt-\"):\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=20,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            move_text = response.choices[0].message.content.strip()\n",
        "        elif model_name.startswith(\"claude-\"):\n",
        "            response = anthropic_client.messages.create(\n",
        "                model=model_name,\n",
        "                max_tokens=20,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            move_text = response.content[0].text.strip()\n",
        "        elif model_name.startswith(\"gemini-\"):\n",
        "            model = genai.GenerativeModel(model_name)\n",
        "            response = model.generate_content(prompt)\n",
        "            move_text = response.text.strip()\n",
        "        else:\n",
        "\n",
        "            print(f\"[WARN] Unknown model: {model_name} - defaulting to random move\")\n",
        "            move_text = None\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] API call failed for {model_name}: {e}\")\n",
        "        move_text = f\"ERROR: {e}\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        if move_text:\n",
        "            i, j = map(int, move_text.split())\n",
        "            if 0 <= i <= 2 and 0 <= j <= 2 and board[i][j] == \"\":\n",
        "                board[i][j] = symbol\n",
        "                return board, move_text\n",
        "    except (ValueError, IndexError):\n",
        "        pass\n",
        "\n",
        "    empty = [(x, y) for x in range(3) for y in range(3) if board[x][y] == \"\"]\n",
        "    if empty:\n",
        "        i, j = random.choice(empty)\n",
        "        board[i][j] = symbol\n",
        "        fallback_msg = f\"LLM invalid move ('{move_text}'). Placed '{symbol}' at fallback {i} {j}.\"\n",
        "        return board, fallback_msg\n",
        "\n",
        "    return board, move_text"
      ],
      "metadata": {
        "id": "13PhMjUbRpEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_turn(player1_model, player2_model, board_state, turn):\n",
        "    \"\"\"Handles one turn of the game.\"\"\"\n",
        "\n",
        "    if not player1_model or not player2_model:\n",
        "        return board_state, \"Please select both players\", turn, render_board_markdown(board_state), \"N/A\"\n",
        "\n",
        "    winner = check_winner(board_state)\n",
        "    if winner:\n",
        "        return board_state, f\"Game Over! Winner: {winner}\", turn, render_board_markdown(board_state), \"Game Over\"\n",
        "\n",
        "    current_symbol = \"X\" if turn % 2 == 0 else \"O\"\n",
        "    current_model_name = player1_model if current_symbol == \"X\" else player2_model\n",
        "    mapped_model = model_map(current_model_name)\n",
        "\n",
        "    llm_raw_output = \"Thinking...\"\n",
        "    try:\n",
        "        updated_board_state, llm_raw_output = llm_move(board_state, current_symbol, model_name=mapped_model)\n",
        "    except Exception as e:\n",
        "        return board_state, f\"Error during LLM move: {str(e)}\", turn, render_board_markdown(board_state), f\"Error: {e}\"\n",
        "\n",
        "    winner = check_winner(updated_board_state)\n",
        "    if winner:\n",
        "        return updated_board_state, f\"Game Over! Winner: {winner}\", turn, render_board_markdown(updated_board_state), llm_raw_output\n",
        "    else:\n",
        "        return updated_board_state, f\"Turn {turn + 1}: {current_model_name} played {current_symbol}\", turn + 1, render_board_markdown(updated_board_state), llm_raw_output\n"
      ],
      "metadata": {
        "id": "7whcGCPjRr5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_game():\n",
        "    \"\"\"Resets the game to its initial state.\"\"\"\n",
        "    new_board = empty_board()\n",
        "    return new_board, \"Press 'Next Turn' to start\", 0, render_board_markdown(new_board), \"N/A\""
      ],
      "metadata": {
        "id": "fOIrpP8oRuYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehan-yviQr57"
      },
      "outputs": [],
      "source": [
        "def get_available_models(selected_model):\n",
        "    \"\"\"Filters available models based on the other selected model.\"\"\"\n",
        "    models = [m for m in LLM_FRONTIERS if m != selected_model]\n",
        "    return models if models else LLM_FRONTIERS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¤– Tic Tac Toe: Two LLM Frontiers Play\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            player1_model = gr.Dropdown(choices=LLM_FRONTIERS, label=\"Player 1 Model (X)\")\n",
        "        with gr.Column():\n",
        "            player2_model = gr.Dropdown(choices=LLM_FRONTIERS, label=\"Player 2 Model (O)\")\n",
        "\n",
        "    player1_model.change(lambda sel: gr.update(choices=get_available_models(sel)), inputs=player1_model, outputs=player2_model)\n",
        "    player2_model.change(lambda sel: gr.update(choices=get_available_models(sel)), inputs=player2_model, outputs=player1_model)\n",
        "\n",
        "    board_state = gr.State(value=empty_board())\n",
        "    turn = gr.State(value=0)\n",
        "\n",
        "    status = gr.Textbox(label=\"Game Status\", value=\"Press 'Next Turn' to start\")\n",
        "    board_markdown = gr.Markdown(value=render_board_markdown(empty_board()), label=\"Board\")\n",
        "    llm_raw_output_display = gr.Textbox(label=\"Last LLM Raw Output\", value=\"N/A\", lines=3, interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        next_btn = gr.Button(\"Next Turn\")\n",
        "        reset_btn = gr.Button(\"Reset Game\")\n",
        "\n",
        "    next_btn.click(\n",
        "        fn=play_turn,\n",
        "        inputs=[player1_model, player2_model, board_state, turn],\n",
        "        outputs=[board_state, status, turn, board_markdown, llm_raw_output_display]\n",
        "    )\n",
        "\n",
        "    reset_btn.click(\n",
        "        fn=reset_game,\n",
        "        inputs=[],\n",
        "        outputs=[board_state, status, turn, board_markdown, llm_raw_output_display]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "4373GcxMQ7Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(inbrowser=True)"
      ],
      "metadata": {
        "id": "XY2jXM8yRyyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grsB8qcgQv_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}